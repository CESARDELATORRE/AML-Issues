{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/classification-credit-card-fraud/auto-ml-classification-credit-card-fraud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "_**Classification of credit card fraudulent transactions with local run **_\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train](#Train)\n",
    "1. [Results](#Results)\n",
    "1. [Test](#Test)\n",
    "1. [Acknowledgements](#Acknowledgements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example we use the associated credit card dataset to showcase how you can use AutoML for a simple classification problem. The goal is to predict if a credit card transaction is considered a fraudulent charge.\n",
    "\n",
    "This notebook is using the local machine compute to train the model.\n",
    "\n",
    "If you are using an Azure Machine Learning [Notebook VM](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup), you are all set. Otherwise, go through the [configuration](../../../configuration.ipynb) notebook first if you haven't already to establish your connection to the AzureML Workspace. \n",
    "\n",
    "In this notebook you will learn how to:\n",
    "1. Create an experiment using an existing workspace.\n",
    "2. Configure AutoML using `AutoMLConfig`.\n",
    "3. Train the model.\n",
    "4. Explore the results.\n",
    "5. Test the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As part of the setup you have already created an Azure ML `Workspace` object. For Automated ML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>672be801-622a-4828-aa13-743ec59b8e29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>aibuilder-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>aibuilder-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>westcentralus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>automl-onn-pickle-perf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "SDK version      1.0.85                              \n",
       "Subscription ID  672be801-622a-4828-aa13-743ec59b8e29\n",
       "Workspace        aibuilder-dev                       \n",
       "Resource Group   aibuilder-dev                       \n",
       "Location         westcentralus                       \n",
       "Experiment Name  automl-onn-pickle-perf              "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'automl-onn-pickle-perf'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=50000, n_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns = [f\"f_{i}\" for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_30</th>\n",
       "      <th>f_31</th>\n",
       "      <th>f_32</th>\n",
       "      <th>f_33</th>\n",
       "      <th>f_34</th>\n",
       "      <th>f_35</th>\n",
       "      <th>f_36</th>\n",
       "      <th>f_37</th>\n",
       "      <th>f_38</th>\n",
       "      <th>f_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.61</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.58</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.67</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.50</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>1.15</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    f_0   f_1   f_2   f_3   f_4   f_5   f_6   f_7   f_8   f_9  ...   f_30  \\\n",
       "0 -0.24 1.83  0.13  -2.36 0.55  0.55  -0.93 0.82  -0.18 0.50   ...  0.89    \n",
       "1 1.61  0.10  -1.32 1.20  -0.69 -0.59 -0.32 -0.74 0.23  0.56   ...  0.05    \n",
       "2 -0.95 -0.06 0.18  2.58  -1.60 0.68  -1.08 0.28  -0.56 -0.76  ...  -0.71   \n",
       "3 0.67  1.79  0.87  -0.27 1.16  -1.18 -0.38 0.94  -0.88 0.05   ...  0.22    \n",
       "4 1.50  -1.65 1.15  -1.90 -0.60 0.44  1.49  0.61  1.33  -0.35  ...  0.62    \n",
       "\n",
       "   f_31  f_32  f_33  f_34  f_35  f_36  f_37  f_38  f_39  \n",
       "0 -1.88 -1.40 0.54  -1.24 -2.14 0.18  0.72  0.48  -0.01  \n",
       "1 0.01  0.85  0.89  1.70  0.34  -1.38 -0.07 -0.48 0.93   \n",
       "2 -0.66 0.36  -0.49 2.01  1.68  1.09  0.21  -0.35 0.74   \n",
       "3 0.88  -0.38 0.79  0.07  0.89  1.47  0.27  0.59  2.16   \n",
       "4 1.00  0.76  0.48  -1.49 0.08  0.16  0.66  -0.52 -1.00  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Load the credit card dataset from a csv file containing both training features and labels. The features are inputs to the model, while the training labels represent the expected output of the model. Next, we'll split the data using random_split and extract the training data for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate a AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**enable_early_stopping**|Stop the run if the metric score is not showing improvement.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|**training_data**|Input dataset, containing both features and label column.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "\n",
    "**_You can find more information about primary metrics_** [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train#primary-metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - The AutoMLConfig inputs you have specified will soon be deprecated. Please use the AutoMLConfig shown in our documentation: https://aka.ms/AutoMLConfig\n"
     ]
    }
   ],
   "source": [
    "automl_settings = {\n",
    "    # \"n_cross_validations\": 3,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"preprocess\": True,\n",
    "    \"experiment_timeout_hours\": 0.6, # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ability to find the best model possible\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"whitelist_models\": [\"LightGBM\"],\n",
    "    \"iterations\": 1,\n",
    "    \"enable_onnx_compatible_models\": True,\n",
    "    \"enable_stack_ensemble\": False\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `submit` method on the experiment object and pass the run configuration. Depending on the data and the number of iterations this can run for a while.\n",
    "In this example, we specify `show_output = True` to print currently running iterations to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_de8b3217-7085-4f48-a0b7-fc98b5a57120\n",
      "\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Train-Test data split\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Your input data has been split into a training dataset and a holdout test dataset for validation of the model. The test holdout dataset reflects the original distribution of your input data.\n",
      "PARAMETERS:   Dataset : train, Row counts : 45000, Percentage : 90.0\n",
      "              Dataset : test, Row counts : 5000, Percentage : 10.0\n",
      "              \n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Classes are balanced in the training data.\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MinMaxScaler LightGBM                          0:00:14       0.9893    0.9893\n"
     ]
    }
   ],
   "source": [
    "local_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to retrieve a run that already started, use the following code\n",
    "#from azureml.train.automl.run import AutoMLRun\n",
    "#local_run = AutoMLRun(experiment = experiment, run_id = '<replace with your run id>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-onn-pickle-perf</td><td>AutoML_de8b3217-7085-4f48-a0b7-fc98b5a57120</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/automl-onn-pickle-perf/runs/AutoML_de8b3217-7085-4f48-a0b7-fc98b5a57120?wsid=/subscriptions/672be801-622a-4828-aa13-743ec59b8e29/resourcegroups/aibuilder-dev/workspaces/aibuilder-dev\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: automl-onn-pickle-perf,\n",
       "Id: AutoML_de8b3217-7085-4f48-a0b7-fc98b5a57120,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "### Retrieve the Best Model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method on `automl_classifier` returns the best run and the fitted model for the last invocation. Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "        feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
       "        featurization_config=None, force_text_dnn=None,\n",
       "        is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
       "        obser...      silent=True, subsample=1, subsample_for_bin=200000,\n",
       "          subsample_freq=0, verbose=-10))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.explain.model.mimic.mimic_explainer import MimicExplainer\n",
    "from azureml.explain.model.mimic.models.lightgbm_model import LGBMExplainableModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.197920322418213\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "explainer = MimicExplainer(fitted_model, X, LGBMExplainableModel, augment_data=False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, onnx_model = local_run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = \"outputs/model_onnx.json\"\n",
    "onnx_res = best_run._download_artifact_contents_to_string(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"RawColumnNameToOnnxNameMap\": {\"f_0\": \"f_0\", \"f_1\": \"f_1\", \"f_2\": \"f_2\", \"f_3\": \"f_3\", \"f_4\": \"f_4\", \"f_5\": \"f_5\", \"f_6\": \"f_6\", \"f_7\": \"f_7\", \"f_8\": \"f_8\", \"f_9\": \"f_9\", \"f_10\": \"f_10\", \"f_11\": \"f_11\", \"f_12\": \"f_12\", \"f_13\": \"f_13\", \"f_14\": \"f_14\", \"f_15\": \"f_15\", \"f_16\": \"f_16\", \"f_17\": \"f_17\", \"f_18\": \"f_18\", \"f_19\": \"f_19\", \"f_20\": \"f_20\", \"f_21\": \"f_21\", \"f_22\": \"f_22\", \"f_23\": \"f_23\", \"f_24\": \"f_24\", \"f_25\": \"f_25\", \"f_26\": \"f_26\", \"f_27\": \"f_27\", \"f_28\": \"f_28\", \"f_29\": \"f_29\", \"f_30\": \"f_30\", \"f_31\": \"f_31\", \"f_32\": \"f_32\", \"f_33\": \"f_33\", \"f_34\": \"f_34\", \"f_35\": \"f_35\", \"f_36\": \"f_36\", \"f_37\": \"f_37\", \"f_38\": \"f_38\", \"f_39\": \"f_39\"}, \"InputRawColumnSchema\": {\"f_0\": \"floating\", \"f_1\": \"floating\", \"f_2\": \"floating\", \"f_3\": \"floating\", \"f_4\": \"floating\", \"f_5\": \"floating\", \"f_6\": \"floating\", \"f_7\": \"floating\", \"f_8\": \"floating\", \"f_9\": \"floating\", \"f_10\": \"floating\", \"f_11\": \"floating\", \"f_12\": \"floating\", \"f_13\": \"floating\", \"f_14\": \"floating\", \"f_15\": \"floating\", \"f_16\": \"floating\", \"f_17\": \"floating\", \"f_18\": \"floating\", \"f_19\": \"floating\", \"f_20\": \"floating\", \"f_21\": \"floating\", \"f_22\": \"floating\", \"f_23\": \"floating\", \"f_24\": \"floating\", \"f_25\": \"floating\", \"f_26\": \"floating\", \"f_27\": \"floating\", \"f_28\": \"floating\", \"f_29\": \"floating\", \"f_30\": \"floating\", \"f_31\": \"floating\", \"f_32\": \"floating\", \"f_33\": \"floating\", \"f_34\": \"floating\", \"f_35\": \"floating\", \"f_36\": \"floating\", \"f_37\": \"floating\", \"f_38\": \"floating\", \"f_39\": \"floating\"}, \"InputOnnxColumnSchema\": {\"f_0\": \"FloatTensorType\", \"f_1\": \"FloatTensorType\", \"f_2\": \"FloatTensorType\", \"f_3\": \"FloatTensorType\", \"f_4\": \"FloatTensorType\", \"f_5\": \"FloatTensorType\", \"f_6\": \"FloatTensorType\", \"f_7\": \"FloatTensorType\", \"f_8\": \"FloatTensorType\", \"f_9\": \"FloatTensorType\", \"f_10\": \"FloatTensorType\", \"f_11\": \"FloatTensorType\", \"f_12\": \"FloatTensorType\", \"f_13\": \"FloatTensorType\", \"f_14\": \"FloatTensorType\", \"f_15\": \"FloatTensorType\", \"f_16\": \"FloatTensorType\", \"f_17\": \"FloatTensorType\", \"f_18\": \"FloatTensorType\", \"f_19\": \"FloatTensorType\", \"f_20\": \"FloatTensorType\", \"f_21\": \"FloatTensorType\", \"f_22\": \"FloatTensorType\", \"f_23\": \"FloatTensorType\", \"f_24\": \"FloatTensorType\", \"f_25\": \"FloatTensorType\", \"f_26\": \"FloatTensorType\", \"f_27\": \"FloatTensorType\", \"f_28\": \"FloatTensorType\", \"f_29\": \"FloatTensorType\", \"f_30\": \"FloatTensorType\", \"f_31\": \"FloatTensorType\", \"f_32\": \"FloatTensorType\", \"f_33\": \"FloatTensorType\", \"f_34\": \"FloatTensorType\", \"f_35\": \"FloatTensorType\", \"f_36\": \"FloatTensorType\", \"f_37\": \"FloatTensorType\", \"f_38\": \"FloatTensorType\", \"f_39\": \"FloatTensorType\"}}'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "from typing import Any, Tuple\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "class OnnxModelWrapper:\n",
    "    \"\"\"\n",
    "        helper class for prediction when using onnx model\n",
    "    \"\"\"\n",
    "    def __init__(self, onnx_model_bytes: bytes, onnx_input_map: dict):\n",
    "        \"\"\"\n",
    "        :param onnx_model_bytes: the onnx model in bytes\n",
    "        :param onnx_input_map: the onnx_resource dictionary\n",
    "        \"\"\"\n",
    "        self.onnx_model_bytes = onnx_model_bytes\n",
    "        self.onnx_input_map = onnx_input_map\n",
    "        self.wrapper_model = OnnxInferenceHelper(self.onnx_model_bytes, self.onnx_input_map)\n",
    "\n",
    "    def predict(self, X) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        predict by using OnnxInferenceHelper\n",
    "        :param X: features to predict\n",
    "        :returns tuple of <label, prob>\n",
    "        \"\"\"\n",
    "        return self.wrapper_model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X) -> ndarray:\n",
    "        \"\"\"\n",
    "        predict proba by using OnnxInferenceHelper\n",
    "        :param X: features to predict\n",
    "        :returns ndarray of prob\n",
    "        \"\"\"\n",
    "        _, y_prob = self.wrapper_model.predict(X, with_prob=True)\n",
    "        return y_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxrt_wrapper = OnnxModelWrapper(onnx_model.SerializeToString(), json.loads(onnx_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.04661011695862\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "explainer = MimicExplainer(onnxrt_wrapper, X, LGBMExplainableModel, augment_data=False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "tzvikei"
   }
  ],
  "category": "tutorial",
  "compute": [
   "Local"
  ],
  "datasets": [
   "creditcard"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": true,
  "file_extension": ".py",
  "framework": [
   "None"
  ],
  "friendly_name": "Classification of credit card fraudulent transactions using Automated ML",
  "index_order": 5,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "tags": [
   "local_run",
   "AutomatedML"
  ],
  "task": "Classification",
  "version": "3.6.7"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
